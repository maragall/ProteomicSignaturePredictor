{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f31a26-11a1-47a9-9c9e-a3b8d46f3a98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features_df = pd.read_csv(\"/home/j.maragall/PRESENTATION_FEATURES.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Impute all NaN values with 0\n",
    "features_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbeff98-b2ca-42a5-ac91-1fa4ab394db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "\n",
    "# Assuming 'features_df' is your DataFrame and it has been properly defined\n",
    "\n",
    "# Specify your mask dimensions (image dimensions)\n",
    "mask_height = 17448  # Example height\n",
    "mask_width = 4908    # Example width\n",
    "\n",
    "# Create an empty binary mask\n",
    "binary_mask = np.zeros((mask_height, mask_width), dtype=np.uint8)\n",
    "\n",
    "# Fill in the regions specified in the DataFrame, ensuring indices are integers\n",
    "for index, row in features_df.iterrows():\n",
    "    # Convert slice indices to integers\n",
    "    minr = int(row['minr'])\n",
    "    maxr = int(row['maxr'])\n",
    "    minc = int(row['minc'])\n",
    "    maxc = int(row['maxc'])\n",
    "    \n",
    "    # Use these integer values to slice and update the binary mask\n",
    "    binary_mask[minr:maxr, minc:maxc] = 255\n",
    "\n",
    "# Specify the path and file name for the output TIFF file\n",
    "output_file_path = 'features_binary_mask.tif'\n",
    "\n",
    "# Save the binary mask as a TIFF file\n",
    "tifffile.imwrite(output_file_path, binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d925fc8-a6ab-4f5a-b8c7-fcb8d0f09927",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyter/6.5.4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-04 20:48:11.782995: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-04 20:48:16.165389: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imread\n",
    "from PIL import Image\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy.stats import entropy\n",
    "from umap import UMAP\n",
    "import tiffslide as openslide\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def normalize_image(image, target_dtype=np.uint8):\n",
    "    normalized_image = cv2.normalize(image, None, 0, np.iinfo(target_dtype).max, cv2.NORM_MINMAX)\n",
    "    return normalized_image.astype(target_dtype)\n",
    "\n",
    "def load_and_process_images(image1_path, image2_path):\n",
    "    slide1 = openslide.OpenSlide(image1_path)\n",
    "    slide2 = openslide.OpenSlide(image2_path)\n",
    "    img1 = normalize_image(np.array(slide1.get_thumbnail(slide1.dimensions)), np.uint8)\n",
    "    img2 = normalize_image(np.array(slide2.get_thumbnail(slide2.dimensions)), np.uint8)\n",
    "    return img1, img2\n",
    "\n",
    "def compute_homography(img1, img2):\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, d1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, d2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = matcher.knnMatch(d1, d2, k=2)\n",
    "\n",
    "    good_matches = [m for m, n in matches if m.distance < 0.7 * n.distance]\n",
    "\n",
    "    p1 = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    p2 = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    homography, _ = cv2.findHomography(p1, p2, cv2.RANSAC)\n",
    "    return homography\n",
    "\n",
    "def transform_patch(patch, channel_index, homography, patch_size):\n",
    "    single_channel_img = patch[:,:,channel_index]\n",
    "    normalized_single_channel_img = normalize_image(single_channel_img, np.uint8)\n",
    "    transformed_single_channel_img = cv2.warpPerspective(normalized_single_channel_img, homography, (patch_size, patch_size))\n",
    "    return transformed_single_channel_img, channel_index\n",
    "\n",
    "def transform_multichannel_image(multi_channel_img, homography, patch_size=512):\n",
    "    num_patches_width = multi_channel_img.shape[1] // patch_size\n",
    "    num_patches_height = multi_channel_img.shape[0] // patch_size\n",
    "    transformed_channels = [np.zeros_like(multi_channel_img[:, :, 0], dtype=np.uint8) for _ in range(multi_channel_img.shape[2])]\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=20) as executor:\n",
    "        futures = []\n",
    "        for i in range(num_patches_height):\n",
    "            for j in range(num_patches_width):\n",
    "                y_min = i * patch_size\n",
    "                y_max = (i + 1) * patch_size\n",
    "                x_min = j * patch_size\n",
    "                x_max = (j + 1) * patch_size\n",
    "\n",
    "                patch = multi_channel_img[y_min:y_max, x_min:x_max, :]\n",
    "\n",
    "                for channel_index in range(patch.shape[2]):\n",
    "                    futures.append(executor.submit(transform_patch, patch, channel_index, homography, patch_size))\n",
    "                    \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            transformed_single_channel_img, channel_index = future.result()\n",
    "            y_min = i * patch_size\n",
    "            y_max = (i + 1) * patch_size\n",
    "            x_min = j * patch_size\n",
    "            x_max = (j + 1) * patch_size\n",
    "            transformed_channels[channel_index][y_min:y_max, x_min:x_max] = transformed_single_channel_img\n",
    "    \n",
    "    return np.stack(transformed_channels, axis=-1)\n",
    "    return np.stack(transformed_channels, axis=-1)\n",
    "\n",
    "def extract_features(binary_mask_path, registered_multi_channel_img):\n",
    "    image = Image.open(binary_mask_path)\n",
    "    image_array = np.array(image)\n",
    "    labeled_image, number_of_objects = label(image_array == 255, connectivity=2, return_num=True)\n",
    "    \n",
    "    features_list = []\n",
    "\n",
    "    for region_label in range(1, number_of_objects + 1):\n",
    "        object_mask = (labeled_image == region_label)\n",
    "        properties = regionprops(object_mask.astype(int))[0]\n",
    "        area = properties.area\n",
    "        perimeter = properties.perimeter\n",
    "        eccentricity = properties.eccentricity\n",
    "        solidity = properties.solidity\n",
    "        orientation = properties.orientation\n",
    "\n",
    "        channel_features = []\n",
    "\n",
    "        for channel_index in range(registered_multi_channel_img.shape[2]):\n",
    "            single_channel_img = registered_multi_channel_img[:, :, channel_index]\n",
    "            masked_single_channel = single_channel_img * object_mask\n",
    "\n",
    "            mean_intensity = np.mean(masked_single_channel[object_mask])\n",
    "            std_intensity = np.std(masked_single_channel[object_mask])\n",
    "            variance_intensity = np.var(masked_single_channel[object_mask])\n",
    "            hist, _ = np.histogram(masked_single_channel[object_mask], bins=256, range=(0, 256), density=True)\n",
    "            entropy_intensity = entropy(hist)\n",
    "            glcm = graycomatrix(masked_single_channel, [1], [0], symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "\n",
    "            channel_features.extend([mean_intensity, std_intensity, variance_intensity, entropy_intensity, contrast])\n",
    "\n",
    "        features_list.append(channel_features + [area, perimeter, eccentricity, solidity, orientation])\n",
    "\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "def visualize_umap_embedding(features_df):\n",
    "    umap = UMAP(n_neighbors=5, min_dist=0.3, n_components=2, metric='euclidean')\n",
    "    embedding = umap.fit_transform(features_df.values)\n",
    "\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], s=5)\n",
    "    plt.title('UMAP Embedding of Extracted Features')\n",
    "    plt.xlabel('UMAP Dimension 1')\n",
    "    plt.ylabel('UMAP Dimension 2')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths\n",
    "    image1_path = \"/home/j.maragall/Pipeline_CellMapping/features_binary_mask.tif\"\n",
    "    image2_path = \"/home/j.maragall/Pipeline_CellMapping/R2_DAPI_cleaned_mask.tif\"\n",
    "    multi_channel_image_path = \"/blue/pinaki.sarder/j.maragall/Replication1_DAPImapping/15-1.tif\"\n",
    "    binary_mask_path = image2_path\n",
    "    \n",
    "    # Load and process images\n",
    "    img1, img2 = load_and_process_images(image1_path, image2_path)\n",
    "    \n",
    "    # Compute homography\n",
    "    homography = compute_homography(img1, img2)\n",
    "    \n",
    "    # Transform multi-channel image\n",
    "    multi_channel_img = imread(multi_channel_image_path)\n",
    "    registered_multi_channel_img = transform_multichannel_image(multi_channel_img, homography)\n",
    "    \n",
    "    # Extract features\n",
    "    features_df = extract_features(binary_mask_path, registered_multi_channel_img)\n",
    "    \n",
    "    # Visualize UMAP embedding\n",
    "    visualize_umap_embedding(features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a5bb00-3eeb-4e7a-ae37-040887c776ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/j.maragall/Pipeline_CellMapping'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d5276-4654-4754-a385-52afa9178f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
